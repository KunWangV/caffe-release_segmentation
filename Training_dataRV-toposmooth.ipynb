{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atemmar/anaconda2/lib/python2.7/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dicom\n",
    "import os\n",
    "import scipy.ndimage\n",
    "import cv2\n",
    "import time\n",
    "import scipy.misc\n",
    "import caffe\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "import time \n",
    "\n",
    "caffe_root = \"./\"\n",
    "%matplotlib inline\n",
    "\n",
    "size_image = (256, 216, 3)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "rep_dataset = \"/home/atemmar/Documents/Stage_ets/caffe-release_segmentation/dataSet_preprocess/\"\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def normalize_heatmap(heatmap):\n",
    "    heat_map_normalize = np.zeros(heatmap.shape)\n",
    "    for x in range(heatmap.shape[0]):\n",
    "        for y in range(heatmap.shape[1]):\n",
    "            heat_map_normalize[x,y,:] = softmax(heatmap[x,y,:])\n",
    "    \n",
    "    return heat_map_normalize\n",
    "\n",
    "def do_training(solver, step_size):\n",
    "        solver.step(step_size)\n",
    "\n",
    "        heat_map = solver.test_nets[0].blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0)\n",
    "        heat_map_normalize = normalize_heatmap(heat_map)\n",
    "#         heat_map_normalize = heat_map\n",
    "        minimum = np.min(heat_map[:,:,0])\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        image_test = solver.test_nets[0].blobs[\"data\"].data[0].transpose(1,2,0)\n",
    "        image_test_label = solver.test_nets[0].blobs[\"label\"].data[0,0,:,:]\n",
    "        plt.subplot(1,5,1)\n",
    "        plt.imshow(image_test[:,:,0])\n",
    "        plt.title(\"image test\")\n",
    "        plt.subplot(1,5,2)\n",
    "        plt.imshow(image_test_label)\n",
    "        plt.title(\"Label of the test image\")\n",
    "        plt.subplot(1,5,3)\n",
    "        plt.imshow(heat_map_normalize)\n",
    "        plt.title(\"min : \" + str(minimum))\n",
    "        plt.subplot(1,5,4)\n",
    "        plt.imshow(solver.test_nets[0].blobs[\"score\"].data[0,:,:,:].transpose(1,2,0))\n",
    "        plt.title(\"score\")\n",
    "        plt.subplot(1,5,5)\n",
    "        plt.imshow(solver.test_nets[0].blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0).argmax(2), vmin=0, vmax=2)\n",
    "        plt.title(\"After : \" + str(nb_step+step_size) + \" itterations\")\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# rep_traininSet = \"/home/luffy/Documents/Stage/dataSet_preprocess/Train/IRM/\"\n",
    "# rep_label = \"/home/luffy/Documents/Stage/dataSet_preprocess/Train/Segment_GT/\" \n",
    "\n",
    "rep_traininSet = rep_dataset + \"/Train/IRM/\"\n",
    "rep_label = rep_dataset + \"/Train/Segment_GT/\" \n",
    "\n",
    "fileList = [f for f in list(os.walk(rep_traininSet))[0][2] if \".png\" in f.lower()][:1000]\n",
    "\n",
    "nb_image = 0\n",
    "images_irm = np.zeros((size_image[0], size_image[1], size_image[2], len(fileList)))\n",
    "labels = np.zeros((size_image[0], size_image[1], len(fileList)))\n",
    "for filename in fileList:\n",
    "    images_irm[:,:, :,nb_image] = scipy.misc.imread(rep_traininSet + filename)\n",
    "    labels[:,:, nb_image] = scipy.misc.imread(rep_label + filename)\n",
    "    nb_image += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rep_testSet = rep_dataset + \"/Test/IRM/\"\n",
    "rep_label_test = rep_dataset + \"/Test/Segment_GT/\" \n",
    "\n",
    "fileList = [f for f in list(os.walk(rep_testSet))[0][2] if \".png\" in f.lower()]\n",
    "\n",
    "nb_image = 0\n",
    "images_irm_test = np.zeros((size_image[0], size_image[1], size_image[2], len(fileList)))\n",
    "labels_test = np.zeros((size_image[0], size_image[1], len(fileList)))\n",
    "\n",
    "for filename in fileList:\n",
    "    images_irm_test[:,:, :,nb_image] = scipy.misc.imread(rep_testSet + filename)\n",
    "    labels_test[:,:, nb_image] = scipy.misc.imread(rep_label_test + filename)\n",
    "    nb_image += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training fcn perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_cpu()\n",
    "solver_name = caffe_root + \"models/fcn_perso/solver5_topoSmoothloss.prototxt\"\n",
    "solver = caffe.SGDSolver(solver_name)\n",
    "\n",
    "# for each layer, show the output shape\n",
    "for layer_name, blob in solver.net.blobs.iteritems():\n",
    "    print layer_name + '\\t' + str(blob.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "solver_name = caffe_root + \"models/fcn_perso/solver5_softmaxsmooth.prototxt\"\n",
    "solver = caffe.SGDSolver(solver_name)\n",
    "\n",
    "\n",
    "nb_step = 0\n",
    "# rep_model = \"/media/luffy/DATA/Users/abdel/models_pretrained_rv_softmax/\"\n",
    "# rep_model = \"/media/luffy/DATA/Users/abdel/models_pretrained_rv_softmax/perso1/\"\n",
    "rep_model  = \"/home/atemmar/Documents/Stage_ets/caffe-release_segmentation/models_pretrained_rv/perso/\"\n",
    "# weight_softmax = rep_model + 'train_perso52_Topo_pretrained_augmented_softmax_iter_300000.caffemodel'\n",
    "# solver_softmax = rep_model + 'train_perso6_Topo_pretrained_augmented_softmax_iter_100000.solverstate'\n",
    "# solver_softmax = rep_model + 'train_perso5_hist_Topo_pretrained_augmented_softmaxsmooth_iter_' + str(nb_step) + '.solverstate'\n",
    "# solver.restore(solver_softmax)\n",
    "# solver.net.copy_from(weight_softmax)\n",
    "\n",
    "# solver.step(1)\n",
    "\n",
    "\n",
    "do_training(solver=solver, step_size=1)\n",
    "# image_test = solver.test_nets[0].blobs[\"data\"].data[0,0,:,:]\n",
    "# image_test_label = solver.test_nets[0].blobs[\"label\"].data[0,0,:,:]\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(image_test)\n",
    "# plt.title(\"image test\")\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(image_test_label)\n",
    "# plt.title(\"Label of the test image\")\n",
    "\n",
    "value_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "solver.test_nets[0].blobs[\"label\"].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "step_size = 500\n",
    "for i in range(20*10):\n",
    "    do_training(solver=solver, step_size=step_size)\n",
    "    nb_step += step_size\n",
    "#     value_loss.append(solver.test_nets[0].blobs[\"loss\"].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "solver.test_nets[0].blobs[\"score-final\"].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "model_def = caffe_root + '/models/fcn_perso/fcn_perso5_softmaxloss.prototxt'\n",
    "# model_weights = caffe_root + 'models/bvlc_alexnet_FCN_wTOPO/alexnet_LT.caffemodel'\n",
    "model_weights = caffe_root + 'train_alexnet_Topo_pretrained_softmax_iter_30000.caffemodel'\n",
    "\n",
    "\n",
    "# net = caffe.Net(model_def,      # defines the structure of the model\n",
    "#                 model_weights, caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "# net = solver.net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Result on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "nb_images = 100\n",
    "indices = list(range(nb_images))\n",
    "images_to_test = indices[:100]\n",
    "\n",
    "net = solver.net\n",
    "for num_image_train in images_to_test:\n",
    "#     img = images_irm[:,:,:,num_image_train].transpose(2,0,1)\n",
    "#     label = labels[:,:, num_image_train]\n",
    "\n",
    "\n",
    "#     net.blobs['data'].data[...] = img\n",
    "    net.forward()\n",
    "    out = net.blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0)\n",
    "    label_out = out.argmax(axis=2)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(net.blobs['data'].data[0].transpose(1,2,0)[:,:,0])\n",
    "    plt.title(\"Orginial image\")\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(net.blobs['label'].data[0,0,:,:], vmin=0, vmax=2)\n",
    "    plt.title(\"Ground truth segmentation\")\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(normalize_heatmap(out))\n",
    "    plt.title(\"Heat map\")\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(label_out, vmin=0, vmax=2)\n",
    "    plt.title(\"Segmentation predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result without histogram transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_weights = rep_model + 'train_perso52_Topo_pretrained_augmented_softmax_iter_100000.caffemodel'\n",
    "net_ = caffe.Net(model_def,      # defines the structure of the model\n",
    "            model_weights, caffe.TRAIN)     # use test mode (e.g., don't perform dropout)\n",
    "\n",
    "nb_images = 100\n",
    "indices = list(range(nb_images))\n",
    "images_to_test = indices[:100]\n",
    "\n",
    "net = solver.net\n",
    "for num_image_train in images_to_test:\n",
    "#     img = images_irm[:,:,:,num_image_train].transpose(2,0,1)\n",
    "#     label = labels[:,:, num_image_train]\n",
    "\n",
    "\n",
    "#     net.blobs['data'].data[...] = img\n",
    "    net_.forward()\n",
    "    out = net_.blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0)\n",
    "    label_out = out.argmax(axis=2)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(net_.blobs['data'].data[0].transpose(1,2,0)[:,:,0])\n",
    "    plt.title(\"Orginial image\")\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(net_.blobs['label'].data[0,0,:,:], vmin=0, vmax=2)\n",
    "    plt.title(\"Ground truth segmentation\")\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(normalize_heatmap(out))\n",
    "    plt.title(\"Heat map\")\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(label_out, vmin=0, vmax=2)\n",
    "    plt.title(\"Segmentation predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Results on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##### import random\n",
    "\n",
    "nb_images = 25\n",
    "indices = list(range(nb_images))\n",
    "images_to_test = indices\n",
    "\n",
    "net = solver.test_nets[0]\n",
    "for num_image_test in images_to_test:\n",
    "#     img = images_irm_test[:,:,:,num_image_test].transpose(2,0,1)\n",
    "#     label = labels_test[:,:, num_image_test]\n",
    "\n",
    "#     net.blobs['data'].data[...] = img\n",
    "    net.forward()\n",
    "    \n",
    "    out = net.blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0)\n",
    "    label_out = out.argmax(axis=2)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(net.blobs['data'].data[0].transpose(1,2,0)[:,:,0])\n",
    "    plt.title(\"Orginial image\")\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(net.blobs['label'].data[0,0,:,:], vmin=0, vmax=2)\n",
    "    plt.title(\"Ground truth segmentation\")\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(normalize_heatmap(out))\n",
    "    plt.title(\"Heat map\")\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(label_out, vmin=0, vmax=2)\n",
    "    plt.title(\"Segmentation predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the parameters are a list of [weights, biases]\n",
    "net = solver.net\n",
    "conv1 = net.blobs['score'].data\n",
    "\n",
    "# plt.figure(figsize=(30,30))\n",
    "plt.figure(figsize=(20,90))\n",
    "nb_c = min(conv1.shape[1],10)\n",
    "for i in range(conv1.shape[1]):\n",
    "    plt.subplot(20,nb_c,i+1)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "    plt.imshow(conv1[0,i,:,:], cmap='jet')\n",
    "    plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(net.blobs['score'].data[0,1:].argmax(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.blobs['conv9'].data[0].transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Depending on the number of itterations done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load all the nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nb_itterations = [2000, 20000, 60000, 100000, 140000, 180000, 200000, 220000, 260000, 300000]\n",
    "\n",
    "model_def = caffe_root + 'models/fcn_perso/fcn5_deploy_softmaxloss.prototxt'\n",
    "rep_model = \"/home/atemmar/Documents/Stage_ets/caffe-release_segmentation/models_pretrained_rv/perso/\"\n",
    "\n",
    "\n",
    "weight_softmax = rep_model + 'train_perso52_Topo_pretrained_augmented_softmax_iter_300000.caffemodel'\n",
    "\n",
    "nets = []\n",
    "\n",
    "# solver_name = caffe_root + \"models/fcn_perso/solver5_softmax.prototxt\"\n",
    "# solver = caffe.SGDSolver(solver_name)\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "for nb_itter in nb_itterations:\n",
    "    model_weights = rep_model + 'train_perso52_Topo_pretrained_augmented_softmax_iter_' + str(nb_itter) +'.caffemodel'\n",
    "#     solver.restore(model_solver)\n",
    "#     net = solver.net\n",
    "    net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights, caffe.TEST)     # use test mode (e.g., don't perform dropout)\n",
    "    nets.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nbs_nets = len(nets)\n",
    "nb_columns_display = 2 + nbs_nets\n",
    "\n",
    "for num_image_test in range(images_irm_test.shape[3]):\n",
    "    img = images_irm_test[:,:,0,num_image_test]\n",
    "    \n",
    "    max_img, min_img = np.max(img), np.min(img)\n",
    "    img = 2*(img-max_img)/(max_img - min_img) - 1\n",
    "    \n",
    "    label = labels_test[:,:, num_image_test]\n",
    "\n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.subplot(1,nb_columns_display,1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Orginial image\")\n",
    "    plt.subplot(1,nb_columns_display,2)\n",
    "    plt.imshow(label, vmin=0, vmax=2)\n",
    "    plt.title(\"Ground truth segmentation\")\n",
    "    for i, net in enumerate(nets):\n",
    "        net.blobs['data'].data[...] = img\n",
    "        net.forward()\n",
    "        out = net.blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0)\n",
    "        label_out = out.argmax(axis=2)\n",
    "        plt.subplot(1,nb_columns_display,2+i+1)\n",
    "        plt.imshow(normalize_heatmap(out))\n",
    "        plt.title(\"Segmentation predicted after \" + str (nb_itterations[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nets[-1].blobs['data'].data[...] = img\n",
    "nets[-1].forward()\n",
    "out = nets[-1].blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.sum(out.argmax(axis=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Pixel wise accuaracy depending on the number of itterations done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuaracy_depending_nbItterations = np.zeros(len(nets), dtype=np.float)\n",
    "\n",
    "def compute recall(label, label_predicted):\n",
    "    right_prediction = (label == label_predicted).astype(int)\n",
    "    nb_pos_predict = nb.sum(right_prediction[label != 0])\n",
    "    nb_pos = np.sum((label != 0).astype(int))\n",
    "    \n",
    "    return float(nb_pos_predict/nb_pos)\n",
    "\n",
    "for num_image_test in range(images_irm_test.shape[3]):\n",
    "    img = images_irm_test[:,:,:,num_image_test].transpose(2,0,1)\n",
    "    label = labels_test[:,:, num_image_test]\n",
    "    for i, net in enumerate(nets):\n",
    "        net.blobs['data'].data[...] = img\n",
    "        net.forward()\n",
    "        out = net.blobs[\"score-final\"].data[0,:,:,:].transpose(1,2,0)\n",
    "        label_predicted = out.argmax(axis=2)\n",
    "        accuaracy_depending_nbItterations[i] += np.sum((label == label_predicted).astype(int))/float(label.size)\n",
    "\n",
    "accuaracy_depending_nbItterations /= images_irm_test.shape[3]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(nb_itterations, accuaracy_depending_nbItterations)\n",
    "plt.title(\"Pixel wise accuaracy depending on the number of itterations done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for each layer, show the output shape\n",
    "for layer_name, blob in net.blobs.iteritems():\n",
    "    print layer_name + '\\t' + str(blob.data.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
